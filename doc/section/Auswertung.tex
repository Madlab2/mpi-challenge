\section{Auswertung}
Die Autoren erwarten von ideal implementierter Parallelisierung einen messbaren Zusammenhang zwischen der Anzahl der verwendeten Rechenknoten und der resultierenden Laufzeit.
\\
Die im Abschnitt Ergebnisse durchgeführten Messungen lassen darauf schließen, dass Parallelisierung in der für das Projekt durchgeführten Form eine signifikante Absenkung der Laufzeit von bis zu einer Größenordnung von 60\% ermöglicht. Dieser Effekt ist jedoch stark begrenzt und flacht mit einer steigenden Rechenknotenanzahl schnell ab bzw. verschwindet gänzlich. Die Effizienz pro Rechenknoten nimmt daher bei steigender Anzahl von Rechenknoten ab. Für genauere Aussagen ist eine größere Anzahl an Messungen pro Messklasse für nötig.
\\
Eine Deutung für die beobachteten Ergebnisse: die Rechenknoten in der Cloud sind mittels Ethernet miteinander verbunden, was das Senden und Empfangen von Nachrichten erstens nicht zeitlich deterministisch und zweitens anfällig für unregelmäßige und längere Laufzeiten macht. Offenbar bewegt sich bei der kleineren Dateigröße das Senden und Empfangen von Nachrichten an mehr Knoten ab einer Knotenzahl von ca. vier in einer ähnlichen Größenordnungen wie der Laufzeitgewinn, welcher dadurch entsteht, dass ein Rechenknoten nur eine geringere Anzahl an Arbeit (Wörter sortieren) hat. 
\\
Es wird die These aufgestellt, dass bei einer größeren Datei mit mehr Wörtern ein Laufzeitgewinn auch bei größeren Knotenzahlen zu messen sein ist.
Um diese These zu untersuchen, werden die Ergebnisse der Messungen mit beiden Dateigrößen untersucht. Wie in IV. Ergebnisse erläutert verschiebt sich die Knotenzahl, ab der keine weitere Zeitreduktion zu messen ist, mit der größeren Datei von vier auf fünf. Dies widerlegt die Antithese, dass mehr Rechenaufwand sich \textit{nicht} auf den Auftretenszeitpunkt dieses Effektes auswirkt und untermauert die aufgestellte These.
\\
Während bei der kleineren Datei sich die Laufzeiten bei ausreichender Knotenzahl im Bereich von $1.6\text{s}$ einpendeln, werden bei doppelter Wörteranzahl etwa $5\text{s}$ benötigt. Der zugrunde liegende Merge Sort Algorithmus ist Teil der Komplexitätsklasse ${\mathcal{O}(n\log{n})}$. Es ist damit zu erwarten, dass die Laufzeiten bei gleicher Knotenzahl sich mehr als verdoppeln, also überlinear steigen. Dies wird durch die Mittelwerte für beide Dateigrößen in Tabelle 1 bestätigt. Bei gleicher Knotenzahl benötigt die Datei mit doppelter Länge bei jeder Knotenzahl mehr als die doppelte Laufzeit verglichen zur kleineren Dateigröße.
\\
Es wird die These untersucht, dass mit mehr Knoten die größere Wörteranzahl (und damit ein größerer Arbeitsaufwand) durch Parallelisierung kompensiert wird. Die Anzahl der Wörter, welche jeder Knoten im Fall \textit{kleine Datei, 3 Rechenknoten} und im Fall \textit{große Datei, 6 Rechenknoten} zu sortieren hat, ist identisch. Die benötigten mittleren Zeiten, $~2\text{s}$ vs.$~6\text{s}$ unterscheiden sich signifikant und widerlegen die These. Die Autoren vermuten die Funktion \textit{merge\_back()} als primäre und den erhöhten Sende- und Empfangsaufwand als sekundäre Erklärung hierfür. Grund hierfür ist, dass die Funktion \textit{merge\_back()} allein auf dem Master Knoten läuft. Entsprechend werden hier die Vorteile der Parallelisierung nicht genutzt. Bei Betrachtung von \textit{merge\_back()} ist zudem zu erkennen, dass die Laufzeit der Funktion von der Größe der zu sortierenden, vorsortierten Einzelelemente abhängt. Bei doppelter Wörterzahl sind doppelt so viele vorsortierte Wörtergruppen zu sortieren. Daher wäre aus Sicht der Autoren eine Erweiterung Funktion \textit{merge\_back()} um eine Parallelisierungsstrategie ein Angriffspunkt, um das Programm für große Wörterzahlen weiter zu optimieren.